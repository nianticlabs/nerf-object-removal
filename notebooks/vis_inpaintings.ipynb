{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ba72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# load test frame,\n",
    "def load_test_frame_files(file):\n",
    "    with open(file, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    fs = meta['frames']\n",
    "    fs = sorted(fs, key=lambda d: d['file_path'])\n",
    "    \n",
    "    frames = []\n",
    "    for frame in fs:\n",
    "        frames.append(frame['file_path'])\n",
    "    return frames\n",
    "\n",
    "def format_axes(axes):\n",
    "    for ax in axes:\n",
    "        if type(ax) is np.ndarray:\n",
    "            format_axes(ax)\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "def weighted_percentile(x, w, ps, assume_sorted=False):\n",
    "    \"\"\"Compute the weighted percentile(s) of a single vector.\"\"\"\n",
    "    x = x.reshape([-1])\n",
    "    w = w.reshape([-1])\n",
    "    if not assume_sorted:\n",
    "        sortidx = np.argsort(x)\n",
    "    x, w = x[sortidx], w[sortidx]\n",
    "    acc_w = np.cumsum(w)\n",
    "    return np.interp(np.array(ps) * (acc_w[-1] / 100), acc_w, x)\n",
    "            \n",
    "def visualize_cmap(value,\n",
    "                   weight,\n",
    "                   colormap,\n",
    "                   lo=None,\n",
    "                   hi=None,\n",
    "                   percentile=99.,\n",
    "                   curve_fn=lambda x: x,\n",
    "                   modulus=None,\n",
    "                   matte_background=True):\n",
    "    \"\"\"Visualize a 1D image and a 1D weighting according to some colormap.\n",
    "\n",
    "    Args:\n",
    "    value: A 1D image.\n",
    "    weight: A weight map, in [0, 1].\n",
    "    colormap: A colormap function.\n",
    "    lo: The lower bound to use when rendering, if None then use a percentile.\n",
    "    hi: The upper bound to use when rendering, if None then use a percentile.\n",
    "    percentile: What percentile of the value map to crop to when automatically\n",
    "      generating `lo` and `hi`. Depends on `weight` as well as `value'.\n",
    "    curve_fn: A curve function that gets applied to `value`, `lo`, and `hi`\n",
    "      before the rest of visualization. Good choices: x, 1/(x+eps), log(x+eps).\n",
    "    modulus: If not None, mod the normalized value by `modulus`. Use (0, 1]. If\n",
    "      `modulus` is not None, `lo`, `hi` and `percentile` will have no effect.\n",
    "    matte_background: If True, matte the image over a checkerboard.\n",
    "\n",
    "    Returns:\n",
    "    A colormap rendering.\n",
    "    \"\"\"\n",
    "    # Identify the values that bound the middle of `value' according to `weight`.\n",
    "    lo_auto, hi_auto = weighted_percentile(\n",
    "      value, weight, [50 - percentile / 2, 50 + percentile / 2])\n",
    "\n",
    "    # If `lo` or `hi` are None, use the automatically-computed bounds above.\n",
    "    eps = np.finfo(np.float32).eps\n",
    "    lo = lo or (lo_auto - eps)\n",
    "    hi = hi or (hi_auto + eps)\n",
    "\n",
    "    # Curve all values.\n",
    "    value, lo, hi = [curve_fn(x) for x in [value, lo, hi]]\n",
    "\n",
    "    # Wrap the values around if requested.\n",
    "    if modulus:\n",
    "        value = np.mod(value, modulus) / modulus\n",
    "    else:\n",
    "        # Otherwise, just scale to [0, 1].\n",
    "        value = np.nan_to_num(\n",
    "        np.clip((value - np.minimum(lo, hi)) / np.abs(hi - lo), 0, 1))\n",
    "\n",
    "    if colormap:\n",
    "        colorized = colormap(value)[:, :, :3]\n",
    "    else:\n",
    "        assert len(value.shape) == 3 and value.shape[-1] == 3\n",
    "        colorized = value\n",
    "\n",
    "    return colorized\n",
    "\n",
    "depth_curve_fn = lambda x: -np.log(x + np.finfo(np.float32).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to experiments and groundtruth data here\n",
    "EXPERIMENT_DIR = '/mnt/res_nas/silvanweder/experiments' # set this to where you saved your experiments to\n",
    "GROUNDTRUTH_DIR = '/mnt/res_nas/silvanweder/datasets/object-removal-custom-clean' # set this to where you saved your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Available Experiments:')\n",
    "for exp in os.listdir(EXPERIMENT_DIR):\n",
    "    if exp.startswith('.'):\n",
    "        continue\n",
    "    print('\\t -', exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1671b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select experiments from available experiments above\n",
    "experiment = 'final_tests_real'\n",
    "suffix = '_real' # set to either _real or _synthetic depending on what masks you used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10016080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Available Sequences:')\n",
    "for sc in os.listdir(os.path.join(EXPERIMENT_DIR, experiment)):\n",
    "    print(f'\\t- {sc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0729c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set available sequence here\n",
    "sequence = '003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = os.path.join(EXPERIMENT_DIR, experiment, sequence)\n",
    "groundtruth_path = os.path.join(GROUNDTRUTH_DIR, sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed32210",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted(os.listdir(os.path.join(experiment_path, f'lama_images_output{suffix}')))\n",
    "for imf in image_files:\n",
    "    frame_id = imf.split('_')[0]\n",
    "    \n",
    "    img_path = os.path.join(groundtruth_path, f'images', f'{frame_id}.jpg')\n",
    "    img_inp_path = os.path.join(experiment_path, f'lama_images_output{suffix}', imf)\n",
    "    mask_path = os.path.join(groundtruth_path, f'masks{suffix}', f'{frame_id}.npy')\n",
    "    print(mask_path)\n",
    "    \n",
    "    img = np.asarray(Image.open(img_path))\n",
    "    img = cv2.resize(img, (256, 192))\n",
    "    \n",
    "    mask = np.load(mask_path)\n",
    "    img_inp = np.asarray(Image.open(img_inp_path))\n",
    "    \n",
    "    \n",
    "    \n",
    "    img_masked = img.copy()\n",
    "    img_masked[mask == 1] = (255, 255, 255)\n",
    "    \n",
    "    if rotate:\n",
    "        img = np.rot90(img, k=-1)\n",
    "        img_masked = np.rot90(img_masked, k=-1)\n",
    "        img_inp =  np.rot90(img_inp, k=-1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(img_masked)\n",
    "    ax[2].imshow(img_inp)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:object-removal]",
   "language": "python",
   "name": "conda-env-object-removal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
